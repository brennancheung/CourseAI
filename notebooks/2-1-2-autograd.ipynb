{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Autograd: PyTorch's Gradient Engine\n",
        "\n",
        "In this notebook, you'll build hands-on intuition for how PyTorch computes gradients automatically.\n",
        "\n",
        "**What you'll do:**\n",
        "- Compute gradients for a polynomial and verify by hand\n",
        "- Reproduce a backprop network and compare `.grad` to manual calculation\n",
        "- Discover the gradient accumulation trap and fix it\n",
        "- Write a complete manual training step\n",
        "- Use `detach()` to surgically stop gradient flow\n",
        "\n",
        "**For each exercise, PREDICT the output before running the cell.** Wrong predictions are more valuable than correct ones — they reveal gaps in your mental model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For nice plots\n",
        "plt.style.use('dark_background')\n",
        "plt.rcParams['figure.figsize'] = [10, 4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 1: Polynomial Gradient (Guided)\n",
        "\n",
        "Let's start simple. We'll compute the gradient of a polynomial and verify it by hand.\n",
        "\n",
        "Given: $y = x^3 + 2x^2 - 5x + 1$\n",
        "\n",
        "The derivative is: $\\frac{dy}{dx} = 3x^2 + 4x - 5$\n",
        "\n",
        "At $x = 3$: $\\frac{dy}{dx} = 3(9) + 4(3) - 5 = 27 + 12 - 5 = 34$\n",
        "\n",
        "**Before running the cell below, predict:** What will `x.grad` be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create a tensor with requires_grad=True so PyTorch tracks operations on it\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "# Forward pass: compute the polynomial\n",
        "y = x**3 + 2*x**2 - 5*x + 1\n",
        "\n",
        "# Backward pass: compute dy/dx\n",
        "y.backward()\n",
        "\n",
        "# Check the gradient\n",
        "print(f\"y = x^3 + 2x^2 - 5x + 1\")\n",
        "print(f\"At x = {x.item()}:\")\n",
        "print(f\"  y            = {y.item()}\")\n",
        "print(f\"  x.grad (PyTorch) = {x.grad.item()}\")\n",
        "print(f\"  dy/dx (by hand)  = {3*3**2 + 4*3 - 5}\")\n",
        "print(f\"  Match: {x.grad.item() == 3*3**2 + 4*3 - 5}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What just happened:**\n",
        "- `requires_grad=True` tells PyTorch to record every operation on `x`\n",
        "- When we called `y.backward()`, PyTorch walked the computation graph backwards\n",
        "- It applied the chain rule at each step to compute $\\frac{dy}{dx}$\n",
        "- The result landed in `x.grad`\n",
        "\n",
        "This is the same mechanism that computes gradients for millions of parameters in a neural network. The math is identical — just more chain rule steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 2: Reproduce a Backprop Network (Guided)\n",
        "\n",
        "Now let's reproduce a simple 2-layer computation and compare `.grad` values to what we'd compute by hand.\n",
        "\n",
        "Network:\n",
        "```\n",
        "x = 2.0\n",
        "w1 = 3.0\n",
        "w2 = -1.0\n",
        "b = 0.5\n",
        "\n",
        "h = x * w1          # hidden: 2 * 3 = 6\n",
        "h_act = h + b        # add bias: 6 + 0.5 = 6.5\n",
        "y = h_act * w2       # output: 6.5 * -1 = -6.5\n",
        "```\n",
        "\n",
        "**Manual gradients (chain rule):**\n",
        "\n",
        "- $\\frac{dy}{dw_2} = h_{act} = 6.5$\n",
        "- $\\frac{dy}{dh_{act}} = w_2 = -1$\n",
        "- $\\frac{dy}{db} = \\frac{dy}{dh_{act}} \\cdot \\frac{dh_{act}}{db} = -1 \\cdot 1 = -1$\n",
        "- $\\frac{dy}{dh} = \\frac{dy}{dh_{act}} \\cdot \\frac{dh_{act}}{dh} = -1 \\cdot 1 = -1$\n",
        "- $\\frac{dy}{dw_1} = \\frac{dy}{dh} \\cdot \\frac{dh}{dw_1} = -1 \\cdot x = -1 \\cdot 2 = -2$\n",
        "- $\\frac{dy}{dx} = \\frac{dy}{dh} \\cdot \\frac{dh}{dx} = -1 \\cdot w_1 = -1 \\cdot 3 = -3$\n",
        "\n",
        "**Before running: predict all six `.grad` values.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Set up all values as tensors that track gradients\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "w1 = torch.tensor(3.0, requires_grad=True)\n",
        "w2 = torch.tensor(-1.0, requires_grad=True)\n",
        "b = torch.tensor(0.5, requires_grad=True)\n",
        "\n",
        "# Forward pass (same computation as above)\n",
        "h = x * w1           # hidden\n",
        "h_act = h + b        # add bias\n",
        "y = h_act * w2       # output\n",
        "\n",
        "# Backward pass\n",
        "y.backward()\n",
        "\n",
        "# Compare PyTorch's gradients to our manual calculation\n",
        "print(\"Forward pass:\")\n",
        "print(f\"  h     = x * w1     = {h.item()}\")\n",
        "print(f\"  h_act = h + b      = {h_act.item()}\")\n",
        "print(f\"  y     = h_act * w2 = {y.item()}\")\n",
        "print()\n",
        "\n",
        "# Manual expected values\n",
        "expected = {\n",
        "    'x':  -3.0,   # dy/dh * dh/dx = -1 * 3 = -3\n",
        "    'w1': -2.0,   # dy/dh * dh/dw1 = -1 * 2 = -2\n",
        "    'w2':  6.5,   # dy/dw2 = h_act = 6.5\n",
        "    'b':  -1.0,   # dy/dh_act * dh_act/db = -1 * 1 = -1\n",
        "}\n",
        "\n",
        "print(f\"{'Variable':<8} {'PyTorch .grad':>15} {'Manual calc':>15} {'Match':>8}\")\n",
        "print(\"-\" * 50)\n",
        "for name, tensor in [('x', x), ('w1', w1), ('w2', w2), ('b', b)]:\n",
        "    grad = tensor.grad.item()\n",
        "    manual = expected[name]\n",
        "    match = abs(grad - manual) < 1e-6\n",
        "    print(f\"{name:<8} {grad:>15.4f} {manual:>15.4f} {str(match):>8}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key insight:** Autograd is doing exactly the chain rule you'd do by hand. It's not magic — it's bookkeeping. Each `.grad` is $\\frac{d(\\text{output})}{d(\\text{this variable})}$, computed by multiplying local derivatives along every path from the output back to that variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 3: The Accumulation Trap (Guided)\n",
        "\n",
        "Here's a subtle behavior that catches everyone. PyTorch **accumulates** gradients by default — calling `.backward()` again **adds** to existing `.grad` values instead of replacing them.\n",
        "\n",
        "**Before running each cell, predict what `x.grad` will be.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 1: First backward pass\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "\n",
        "y = x ** 2    # dy/dx = 2x = 6\n",
        "y.backward()\n",
        "\n",
        "print(f\"After first backward():\")\n",
        "print(f\"  x.grad = {x.grad.item()}\")\n",
        "print(f\"  Expected: 6.0 (2 * 3)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 2: Second backward pass WITHOUT zero_grad\n",
        "# PREDICT: What will x.grad be?\n",
        "\n",
        "y = x ** 2    # dy/dx = 2x = 6 again\n",
        "y.backward()\n",
        "\n",
        "print(f\"After second backward() (no zero_grad):\")\n",
        "print(f\"  x.grad = {x.grad.item()}\")\n",
        "print(f\"  Expected: 12.0 (6 + 6, accumulated!)\")\n",
        "print()\n",
        "print(\"The gradient ACCUMULATED. PyTorch added 6 to the existing 6.\")\n",
        "print(\"This is by design (useful for RNNs), but a trap if you forget.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Step 3: The fix — zero_grad before backward\n",
        "x.grad.zero_()   # Reset gradient to 0 (in-place)\n",
        "\n",
        "y = x ** 2\n",
        "y.backward()\n",
        "\n",
        "print(f\"After zero_grad() + backward():\")\n",
        "print(f\"  x.grad = {x.grad.item()}\")\n",
        "print(f\"  Expected: 6.0 (fresh gradient, no accumulation)\")\n",
        "print()\n",
        "print(\"RULE: Always zero gradients before each backward pass.\")\n",
        "print(\"In training loops, this is optimizer.zero_grad().\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Why does PyTorch accumulate by default?**\n",
        "\n",
        "Some architectures (like RNNs) call `.backward()` multiple times for a single parameter update. Accumulation makes this natural. But for standard training, you must zero gradients each step or your updates will be wrong.\n",
        "\n",
        "**The pattern you'll use in every training loop:**\n",
        "```python\n",
        "optimizer.zero_grad()   # Clear old gradients\n",
        "loss.backward()         # Compute new gradients\n",
        "optimizer.step()        # Update parameters\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 4: Manual Training Step (Supported)\n",
        "\n",
        "Now put it all together. You'll write a single training step by hand — the same forward-backward-update loop that every deep learning model uses, but without an optimizer.\n",
        "\n",
        "**Task:** Fit a linear model $\\hat{y} = wx + b$ to data generated from $y = 2x + 1$.\n",
        "\n",
        "Fill in the TODO sections. The comments tell you exactly what to do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Generate simple data: y = 2x + 1\n",
        "torch.manual_seed(42)\n",
        "X = torch.linspace(-3, 3, 20)\n",
        "y_true = 2 * X + 1 + torch.randn(20) * 0.3   # true line + noise\n",
        "\n",
        "# Initialize learnable parameters (random starting point)\n",
        "w = torch.tensor(0.0, requires_grad=True)\n",
        "b = torch.tensor(0.0, requires_grad=True)\n",
        "\n",
        "learning_rate = 0.01\n",
        "\n",
        "print(f\"Initial parameters: w = {w.item():.4f}, b = {b.item():.4f}\")\n",
        "print(f\"Target:             w = 2.0, b = 1.0\")\n",
        "print(f\"Learning rate: {learning_rate}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================================\n",
        "# YOUR TASK: Implement the training loop\n",
        "# ============================================================\n",
        "\n",
        "losses = []\n",
        "\n",
        "for step in range(200):\n",
        "    # --- Step 1: Forward pass ---\n",
        "    # Compute predictions: y_pred = w * X + b\n",
        "    y_pred = w * X + b          # TODO: uncomment or write this\n",
        "\n",
        "    # --- Step 2: Compute loss ---\n",
        "    # MSE loss: mean of (y_true - y_pred)^2\n",
        "    loss = ((y_true - y_pred) ** 2).mean()   # TODO: uncomment or write this\n",
        "\n",
        "    # --- Step 3: Backward pass ---\n",
        "    # Compute gradients of loss w.r.t. w and b\n",
        "    loss.backward()             # TODO: uncomment or write this\n",
        "\n",
        "    # --- Step 4: Update parameters ---\n",
        "    # Must use torch.no_grad() so the update itself isn't tracked\n",
        "    with torch.no_grad():       # TODO: uncomment this block\n",
        "        w -= learning_rate * w.grad\n",
        "        b -= learning_rate * b.grad\n",
        "\n",
        "    # --- Step 5: Zero gradients ---\n",
        "    # Without this, gradients accumulate (Exercise 3!)\n",
        "    w.grad.zero_()              # TODO: uncomment or write this\n",
        "    b.grad.zero_()              # TODO: uncomment or write this\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    if (step + 1) % 40 == 0:\n",
        "        print(f\"Step {step+1:3d}: loss = {loss.item():.4f}, w = {w.item():.4f}, b = {b.item():.4f}\")\n",
        "\n",
        "print(f\"\\nFinal: w = {w.item():.4f} (target: 2.0), b = {b.item():.4f} (target: 1.0)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the result\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Loss curve\n",
        "axes[0].plot(losses, linewidth=2)\n",
        "axes[0].set_xlabel('Step')\n",
        "axes[0].set_ylabel('MSE Loss')\n",
        "axes[0].set_title('Training Loss')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Data + learned line\n",
        "with torch.no_grad():\n",
        "    x_line = torch.linspace(-3, 3, 100)\n",
        "    y_line = w * x_line + b\n",
        "\n",
        "axes[1].scatter(X.numpy(), y_true.numpy(), alpha=0.7, label='Data')\n",
        "axes[1].plot(x_line.numpy(), y_line.numpy(), 'r-', linewidth=2,\n",
        "             label=f'Learned: y = {w.item():.2f}x + {b.item():.2f}')\n",
        "axes[1].plot(x_line.numpy(), (2*x_line + 1).numpy(), 'g--', linewidth=2, alpha=0.5,\n",
        "             label='True: y = 2x + 1')\n",
        "axes[1].set_xlabel('x')\n",
        "axes[1].set_ylabel('y')\n",
        "axes[1].set_title('Learned Fit')\n",
        "axes[1].legend()\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What you just built:**\n",
        "\n",
        "Every single training loop in deep learning is this same pattern:\n",
        "\n",
        "1. **Forward:** compute predictions from parameters\n",
        "2. **Loss:** measure how wrong the predictions are\n",
        "3. **Backward:** compute how each parameter contributed to the error\n",
        "4. **Update:** nudge parameters in the direction that reduces error\n",
        "5. **Zero:** clear old gradients so they don't accumulate\n",
        "\n",
        "In practice, `torch.optim` handles steps 4 and 5. But now you know what it's doing under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Exercise 5: Stopping Gradients with `detach()` (Stretch)\n",
        "\n",
        "Sometimes you want gradients to flow through part of a computation but not all of it. `detach()` creates a copy of a tensor that's disconnected from the computation graph.\n",
        "\n",
        "**Task:** Create a chain `a -> b -> c`, detach `b`, and verify that `a` gets no gradient.\n",
        "\n",
        "This is used in practice for things like:\n",
        "- Freezing pretrained layers\n",
        "- Target networks in reinforcement learning\n",
        "- Stop-gradient tricks in contrastive learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# First: WITHOUT detach — gradients flow all the way back\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = a * 3       # b = 6, db/da = 3\n",
        "c = b ** 2      # c = 36, dc/db = 2b = 12\n",
        "\n",
        "c.backward()\n",
        "\n",
        "print(\"WITHOUT detach:\")\n",
        "print(f\"  a = {a.item()}, b = {b.item()}, c = {c.item()}\")\n",
        "print(f\"  a.grad = {a.grad.item()}\")\n",
        "print(f\"  Expected: dc/da = dc/db * db/da = 12 * 3 = 36\")\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Now: WITH detach — gradient flow is severed at b\n",
        "a = torch.tensor(2.0, requires_grad=True)\n",
        "b = a * 3           # b = 6\n",
        "b_detached = b.detach()  # Same value (6), but no connection to a\n",
        "c = b_detached ** 2      # c = 36, but c doesn't know about a\n",
        "\n",
        "c.backward()\n",
        "\n",
        "print(\"WITH detach:\")\n",
        "print(f\"  a = {a.item()}, b_detached = {b_detached.item()}, c = {c.item()}\")\n",
        "print(f\"  a.grad = {a.grad}\")\n",
        "print(f\"  Expected: None (gradient path was severed by detach)\")\n",
        "print()\n",
        "print(\"detach() made b_detached a plain tensor with the same value as b,\")\n",
        "print(\"but with no memory of how it was computed. The chain rule has\")\n",
        "print(\"nowhere to go — so a.grad stays None.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the difference\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 3))\n",
        "\n",
        "# Without detach\n",
        "axes[0].set_xlim(0, 10)\n",
        "axes[0].set_ylim(0, 4)\n",
        "axes[0].annotate('a', xy=(1, 2), fontsize=20, ha='center',\n",
        "                  bbox=dict(boxstyle='round,pad=0.5', facecolor='#4a9eff', alpha=0.8))\n",
        "axes[0].annotate('', xy=(3.5, 2), xytext=(2, 2),\n",
        "                  arrowprops=dict(arrowstyle='->', color='white', lw=2))\n",
        "axes[0].annotate('b = a*3', xy=(5, 2), fontsize=20, ha='center',\n",
        "                  bbox=dict(boxstyle='round,pad=0.5', facecolor='#4a9eff', alpha=0.8))\n",
        "axes[0].annotate('', xy=(7.5, 2), xytext=(6.5, 2),\n",
        "                  arrowprops=dict(arrowstyle='->', color='white', lw=2))\n",
        "axes[0].annotate('c = b^2', xy=(9, 2), fontsize=20, ha='center',\n",
        "                  bbox=dict(boxstyle='round,pad=0.5', facecolor='#4a9eff', alpha=0.8))\n",
        "axes[0].annotate('grad=36', xy=(1, 0.8), fontsize=14, ha='center', color='#00ff88')\n",
        "axes[0].set_title('Without detach: gradients flow through', fontsize=14)\n",
        "axes[0].axis('off')\n",
        "\n",
        "# With detach\n",
        "axes[1].set_xlim(0, 10)\n",
        "axes[1].set_ylim(0, 4)\n",
        "axes[1].annotate('a', xy=(1, 2), fontsize=20, ha='center',\n",
        "                  bbox=dict(boxstyle='round,pad=0.5', facecolor='#666666', alpha=0.8))\n",
        "axes[1].annotate('', xy=(3.5, 2), xytext=(2, 2),\n",
        "                  arrowprops=dict(arrowstyle='->', color='red', lw=2, linestyle='dashed'))\n",
        "axes[1].annotate('X', xy=(2.75, 2.5), fontsize=18, ha='center', color='red', fontweight='bold')\n",
        "axes[1].annotate('b.detach()', xy=(5, 2), fontsize=18, ha='center',\n",
        "                  bbox=dict(boxstyle='round,pad=0.5', facecolor='#4a9eff', alpha=0.8))\n",
        "axes[1].annotate('', xy=(7.5, 2), xytext=(6.8, 2),\n",
        "                  arrowprops=dict(arrowstyle='->', color='white', lw=2))\n",
        "axes[1].annotate('c = b^2', xy=(9, 2), fontsize=20, ha='center',\n",
        "                  bbox=dict(boxstyle='round,pad=0.5', facecolor='#4a9eff', alpha=0.8))\n",
        "axes[1].annotate('grad=None', xy=(1, 0.8), fontsize=14, ha='center', color='red')\n",
        "axes[1].set_title('With detach: gradient flow severed', fontsize=14)\n",
        "axes[1].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "1. **`requires_grad=True`** tells PyTorch to record operations on a tensor, building a computation graph\n",
        "2. **`.backward()`** walks the graph backwards, applying the chain rule to compute gradients for every tensor that requires grad\n",
        "3. **Gradients accumulate** by default — always call `.zero_grad()` (or `optimizer.zero_grad()`) before each backward pass\n",
        "4. **`torch.no_grad()`** disables gradient tracking for operations inside its block — essential for parameter updates and inference\n",
        "5. **`.detach()`** severs a tensor from the computation graph — the value is preserved but the gradient path is cut\n",
        "\n",
        "**The training loop pattern** (you'll use this hundreds of times):\n",
        "```python\n",
        "optimizer.zero_grad()   # Clear old gradients\n",
        "output = model(input)   # Forward pass\n",
        "loss = criterion(output, target)  # Compute loss\n",
        "loss.backward()         # Backward pass (compute gradients)\n",
        "optimizer.step()        # Update parameters\n",
        "```\n",
        "\n",
        "Autograd isn't magic. It's the chain rule, applied systematically. Now you've verified that with your own hands."
      ]
    }
  ]
}
