{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# The Problem Attention Solves\n\n**Module 4.2, Lesson 1** — Attention & the Transformer\n\nIn this notebook you'll:\n- Compute the full attention operation step by step: `softmax(XX^T) X`\n- Verify the attention weight matrix is symmetric (and understand why that's a problem)\n- Visualize attention heatmaps to see which tokens attend to which\n- Demonstrate that separate seeking/offering vectors break symmetry\n- (Stretch) Compute attention on real sentences using pretrained GPT-2 embeddings\n\n**For each exercise, PREDICT the output before running the cell.**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Reproducible results\ntorch.manual_seed(42)\n\n# Nice plots\nplt.style.use('dark_background')\nplt.rcParams['figure.figsize'] = [10, 4]\n\nprint(f\"PyTorch version: {torch.__version__}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Exercise 1: Raw Dot-Product Attention on a Tiny Example (Guided)\n\nWe'll work with 4 tokens, each with an 8-dimensional embedding. The goal: implement `Attention(X) = softmax(XX^T) X` step by step.\n\n**Before running, predict:** If X has shape `[4, 8]`, what shape will `X @ X.T` be? After applying softmax row-wise, will each row sum to 1?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our tiny example: 4 tokens, 8-dim embeddings\n",
    "torch.manual_seed(42)\n",
    "n_tokens = 4\n",
    "embed_dim = 8\n",
    "\n",
    "# Simulated embeddings for: [\"The\", \"cat\", \"sat\", \"here\"]\n",
    "tokens = [\"The\", \"cat\", \"sat\", \"here\"]\n",
    "X = torch.randn(n_tokens, embed_dim)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"\\nEmbeddings:\")\n",
    "for i, token in enumerate(tokens):\n",
    "    print(f\"  {token}: {X[i].tolist()[:4]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Compute the similarity score matrix (XX^T)\n",
    "# Each entry [i, j] is the dot product of embedding i and embedding j\n",
    "\n",
    "scores = X @ X.T  # shape: [4, 4]\n",
    "\n",
    "print(f\"Score matrix shape: {scores.shape}\")\n",
    "print(f\"\\nScore matrix (XX^T):\")\n",
    "print(scores.numpy().round(3))\n",
    "\n",
    "# Verify it's symmetric: score[i,j] == score[j,i]\n",
    "print(f\"\\nIs symmetric? {torch.allclose(scores, scores.T, atol=1e-5)}\")\n",
    "print(\"This is guaranteed: dot(a, b) = dot(b, a) always.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Apply softmax to each ROW to get attention weights\n",
    "# Each row becomes a probability distribution (sums to 1)\n",
    "\n",
    "weights = F.softmax(scores, dim=-1)  # softmax along last dimension (columns)\n",
    "\n",
    "print(f\"Attention weight matrix:\")\n",
    "print(weights.numpy().round(4))\n",
    "\n",
    "# Verify each row sums to 1\n",
    "row_sums = weights.sum(dim=-1)\n",
    "print(f\"\\nRow sums: {row_sums.tolist()}\")\n",
    "print(\"Each row sums to 1 — it's a probability distribution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute the output — weighted average of embeddings for each token\n",
    "\n",
    "output = weights @ X  # shape: [4, 8]\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"\\nOriginal embedding for 'cat': {X[1].tolist()[:4]}...\")\n",
    "print(f\"Attention output for 'cat':    {output[1].tolist()[:4]}...\")\n",
    "print(f\"\\nThe output is DIFFERENT from the input — it's a context-dependent blend.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All three steps in one line:\n",
    "def raw_dot_product_attention(X: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute raw dot-product attention (no Q/K/V projections).\n",
    "    \n",
    "    Attention(X) = softmax(XX^T) X\n",
    "    \n",
    "    Args:\n",
    "        X: Embedding matrix of shape [n_tokens, embed_dim]\n",
    "    \n",
    "    Returns:\n",
    "        Context-dependent representations of shape [n_tokens, embed_dim]\n",
    "    \"\"\"\n",
    "    scores = X @ X.T                       # [n, n] pairwise similarity\n",
    "    weights = F.softmax(scores, dim=-1)     # [n, n] normalized weights per row\n",
    "    output = weights @ X                    # [n, d] weighted average\n",
    "    return output\n",
    "\n",
    "# Verify it matches our step-by-step computation\n",
    "output_oneliner = raw_dot_product_attention(X)\n",
    "print(f\"Matches step-by-step? {torch.allclose(output, output_oneliner, atol=1e-5)}\")\n",
    "print(\"\\nThree matrix operations. That's all attention is.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Exercise 2: Visualize the Attention Heatmap (Guided)\n\nThe attention weight matrix is the core data structure. Let's see it.\n\n**Before running, predict:** Will the diagonal of the attention matrix (each token attending to itself) have the highest weights? Why or why not?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(weights: torch.Tensor, tokens: list[str], title: str = \"Attention Weights\"):\n",
    "    \"\"\"Plot attention weight matrix as a heatmap.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(weights.detach().numpy(), cmap='Purples', vmin=0, vmax=1)\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_xticks(range(len(tokens)))\n",
    "    ax.set_yticks(range(len(tokens)))\n",
    "    ax.set_xticklabels(tokens, fontsize=11)\n",
    "    ax.set_yticklabels(tokens, fontsize=11)\n",
    "    ax.set_xlabel('Attending to', fontsize=12)\n",
    "    ax.set_ylabel('Token', fontsize=12)\n",
    "    \n",
    "    # Add values in cells\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens)):\n",
    "            val = weights[i, j].item()\n",
    "            color = 'white' if val > 0.5 else 'black'\n",
    "            ax.text(j, i, f'{val:.3f}', ha='center', va='center', fontsize=10, color=color)\n",
    "    \n",
    "    plt.colorbar(im, ax=ax, label='Weight')\n",
    "    plt.title(title, fontsize=13)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot our attention weights\n",
    "scores = X @ X.T\n",
    "weights = F.softmax(scores, dim=-1)\n",
    "plot_attention(weights, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the RAW SCORES (before softmax) to see the symmetry clearly\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "\n",
    "# Left: raw scores\n",
    "im0 = axes[0].imshow(scores.detach().numpy(), cmap='RdBu_r', \n",
    "                      vmin=-scores.abs().max().item(), vmax=scores.abs().max().item())\n",
    "axes[0].set_xticks(range(len(tokens)))\n",
    "axes[0].set_yticks(range(len(tokens)))\n",
    "axes[0].set_xticklabels(tokens)\n",
    "axes[0].set_yticklabels(tokens)\n",
    "for i in range(len(tokens)):\n",
    "    for j in range(len(tokens)):\n",
    "        axes[0].text(j, i, f'{scores[i,j]:.2f}', ha='center', va='center', fontsize=10)\n",
    "plt.colorbar(im0, ax=axes[0])\n",
    "axes[0].set_title('Raw Dot-Product Scores (XX\\u1d40)\\n(Symmetric!)', fontsize=12)\n",
    "\n",
    "# Right: after softmax\n",
    "im1 = axes[1].imshow(weights.detach().numpy(), cmap='Purples', vmin=0, vmax=1)\n",
    "axes[1].set_xticks(range(len(tokens)))\n",
    "axes[1].set_yticks(range(len(tokens)))\n",
    "axes[1].set_xticklabels(tokens)\n",
    "axes[1].set_yticklabels(tokens)\n",
    "for i in range(len(tokens)):\n",
    "    for j in range(len(tokens)):\n",
    "        axes[1].text(j, i, f'{weights[i,j]:.3f}', ha='center', va='center', fontsize=10,\n",
    "                     color='white' if weights[i,j] > 0.5 else 'black')\n",
    "plt.colorbar(im1, ax=axes[1])\n",
    "axes[1].set_title('Attention Weights (after softmax)\\n(Rows sum to 1)', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Left matrix is SYMMETRIC: score[i,j] == score[j,i].\")\n",
    "print(\"Right matrix: rows sum to 1, but still driven by symmetric scores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key observation:** The raw score matrix is perfectly symmetric. This means the *raw relevance score* between any two tokens is always the same in both directions. As we’ll see, this is a fundamental limitation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Exercise 3: Confirming Symmetry (Guided)\n\nLet's formally verify the symmetry property and understand exactly why it's a problem.\n\n**Before running, predict:** Is `XX^T` guaranteed to be symmetric for ANY matrix X? (Hint: think about `(AB)^T = B^T A^T`.)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify symmetry for multiple random embeddings\n",
    "for trial in range(5):\n",
    "    X_rand = torch.randn(6, 32)  # 6 tokens, 32 dims\n",
    "    S = X_rand @ X_rand.T\n",
    "    is_sym = torch.allclose(S, S.T, atol=1e-5)\n",
    "    print(f\"Trial {trial+1}: XX^T symmetric? {is_sym}\")\n",
    "\n",
    "print(\"\\nAlways symmetric. This is a mathematical property of XX^T, not a coincidence.\")\n",
    "print(\"dot(a, b) = sum(a_i * b_i) = sum(b_i * a_i) = dot(b, a)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why symmetry is a problem: \"The cat chased the mouse\"\n",
    "# For 'cat', 'chased' is relevant because it tells us what the cat DID.\n",
    "# For 'chased', 'cat' is relevant because it tells us WHO did the chasing.\n",
    "# Different reasons, but the score is always the same.\n",
    "\n",
    "# Let's make this concrete with embeddings that simulate meaning:\n",
    "torch.manual_seed(0)\n",
    "tokens_chase = [\"The\", \"cat\", \"chased\", \"the\", \"mouse\"]\n",
    "X_chase = torch.randn(5, 16)\n",
    "\n",
    "scores_chase = X_chase @ X_chase.T\n",
    "\n",
    "# Compare score(cat -> chased) vs score(chased -> cat)\n",
    "cat_idx, chased_idx = 1, 2\n",
    "print(f\"score(cat, chased) = {scores_chase[cat_idx, chased_idx]:.4f}\")\n",
    "print(f\"score(chased, cat) = {scores_chase[chased_idx, cat_idx]:.4f}\")\n",
    "print(f\"Difference: {abs(scores_chase[cat_idx, chased_idx] - scores_chase[chased_idx, cat_idx]):.8f}\")\n",
    "print(f\"\\nExactly the same. But 'cat' needs 'chased' for a DIFFERENT reason\")\n",
    "print(f\"than 'chased' needs 'cat'. Symmetric scores can't express this.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if tokens had TWO vectors — one for seeking, one for offering?\n",
    "# Then score(A seeking B) = dot(seek_A, offer_B)\n",
    "# And score(B seeking A) = dot(seek_B, offer_A)\n",
    "# These are different because seek_A ≠ offer_A in general.\n",
    "\n",
    "torch.manual_seed(42)\n",
    "n = 5\n",
    "d = 16\n",
    "\n",
    "# Simulate two separate vector types\n",
    "seeking_vectors = torch.randn(n, d)   # what each token looks for\n",
    "offering_vectors = torch.randn(n, d)  # what each token advertises\n",
    "\n",
    "# Score matrix: seeking[i] dot offering[j]\n",
    "asymmetric_scores = seeking_vectors @ offering_vectors.T\n",
    "\n",
    "print(f\"Asymmetric scores symmetric? {torch.allclose(asymmetric_scores, asymmetric_scores.T, atol=1e-5)}\")\n",
    "print(f\"\\nscore(cat seeking chased) = {asymmetric_scores[1, 2]:.4f}\")\n",
    "print(f\"score(chased seeking cat) = {asymmetric_scores[2, 1]:.4f}\")\n",
    "print(f\"Difference: {abs(asymmetric_scores[1, 2] - asymmetric_scores[2, 1]):.4f}\")\n",
    "print(f\"\\nNow the scores are DIFFERENT in each direction!\")\n",
    "print(f\"This is exactly what the next lesson (projections) will achieve.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Exercise 4 (Stretch): Attention with Pretrained GPT-2 Embeddings (Guided)\n\nUse real GPT-2 token embeddings to compute raw dot-product attention and see whether \"bank\" gets different attention patterns in different contexts.\n\n**Before running, predict:** The token \"bank\" has the same embedding regardless of context. After applying raw dot-product attention, will the *output* for \"bank\" be different in \"steep and muddy\" vs. \"raised interest rates\"?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install transformers if needed\n",
    "try:\n",
    "    from transformers import GPT2Tokenizer, GPT2Model\n",
    "except ImportError:\n",
    "    !pip install transformers -q\n",
    "    from transformers import GPT2Tokenizer, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "wte = model.wte.weight.detach()  # [50257, 768]\n",
    "\n",
    "def get_embeddings(sentence: str) -> tuple[torch.Tensor, list[str]]:\n",
    "    \"\"\"Get token embeddings for a sentence from GPT-2's embedding table.\"\"\"\n",
    "    ids = tokenizer.encode(sentence)\n",
    "    token_strs = [tokenizer.decode([tid]) for tid in ids]\n",
    "    embeddings = wte[ids]  # [n_tokens, 768]\n",
    "    return embeddings, token_strs\n",
    "\n",
    "def compute_and_plot_attention(sentence: str):\n",
    "    \"\"\"Compute raw dot-product attention and visualize.\"\"\"\n",
    "    X, tok_strs = get_embeddings(sentence)\n",
    "    \n",
    "    scores = X @ X.T\n",
    "    weights = F.softmax(scores, dim=-1)\n",
    "    output = weights @ X\n",
    "    \n",
    "    plot_attention(weights, tok_strs, f'Attention: \"{sentence}\"')\n",
    "    return X, weights, output, tok_strs\n",
    "\n",
    "print(\"Ready to compute attention on real sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence 1: \"bank\" near terrain words\n",
    "X1, W1, out1, toks1 = compute_and_plot_attention(\"The bank was steep and muddy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence 2: \"bank\" near finance words\n",
    "X2, W2, out2, toks2 = compute_and_plot_attention(\"The bank raised interest rates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the attention output for \"bank\" in both sentences\n",
    "# Find the index of \" bank\" in each\n",
    "bank_idx_1 = toks1.index(\" bank\") if \" bank\" in toks1 else toks1.index(\"bank\")\n",
    "bank_idx_2 = toks2.index(\" bank\") if \" bank\" in toks2 else toks2.index(\"bank\")\n",
    "\n",
    "bank_input_1 = X1[bank_idx_1]\n",
    "bank_input_2 = X2[bank_idx_2]\n",
    "\n",
    "bank_output_1 = out1[bank_idx_1]\n",
    "bank_output_2 = out2[bank_idx_2]\n",
    "\n",
    "# Input embeddings should be IDENTICAL (same token)\n",
    "input_sim = F.cosine_similarity(bank_input_1.unsqueeze(0), bank_input_2.unsqueeze(0)).item()\n",
    "# Output embeddings should differ (different contexts)\n",
    "output_sim = F.cosine_similarity(bank_output_1.unsqueeze(0), bank_output_2.unsqueeze(0)).item()\n",
    "\n",
    "print(f\"Input embedding similarity (should be 1.0): {input_sim:.4f}\")\n",
    "print(f\"Output embedding similarity (should be < 1): {output_sim:.4f}\")\n",
    "print(f\"\\nDifference: {1.0 - output_sim:.4f}\")\n",
    "print(f\"\\nThe attention output for 'bank' is DIFFERENT in different contexts,\")\n",
    "print(f\"even though the input embedding is identical. Context shapes meaning.\")\n",
    "print(f\"\\nBut with raw dot products, the effect is limited — 'bank' can't\")\n",
    "print(f\"*seek* different information in different contexts. The seeking vector\")\n",
    "print(f\"is always the same embedding regardless of context.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare attention patterns for \"bank\" in both contexts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 3))\n",
    "\n",
    "# Sentence 1 attention from \"bank\"\n",
    "w1_bank = W1[bank_idx_1].detach().numpy()\n",
    "axes[0].barh(range(len(toks1)), w1_bank, color='steelblue')\n",
    "axes[0].set_yticks(range(len(toks1)))\n",
    "axes[0].set_yticklabels(toks1)\n",
    "axes[0].set_title('\"bank\" attention in: steep and muddy')\n",
    "axes[0].set_xlabel('Attention weight')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Sentence 2 attention from \"bank\"\n",
    "w2_bank = W2[bank_idx_2].detach().numpy()\n",
    "axes[1].barh(range(len(toks2)), w2_bank, color='coral')\n",
    "axes[1].set_yticks(range(len(toks2)))\n",
    "axes[1].set_yticklabels(toks2)\n",
    "axes[1].set_title('\"bank\" attention in: raised interest rates')\n",
    "axes[1].set_xlabel('Attention weight')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"The patterns differ because the context embeddings differ.\")\n",
    "print(\"But 'bank' uses the SAME seeking vector in both cases.\")\n",
    "print(\"With separate seeking/offering vectors, 'bank' could seek\")\n",
    "print(\"terrain words in one context and finance words in another.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Key Takeaways\n\n1. **Attention is three matrix operations:** `scores = XX^T`, `weights = softmax(scores)`, `output = weights @ X`. Each output token is a weighted average of all input tokens.\n2. **The raw score matrix `XX^T` is always symmetric.** `dot(a, b) = dot(b, a)`, so the relevance score between any two tokens is identical in both directions. This is a mathematical fact, not a coincidence.\n3. **Symmetry is a limitation.** \"Cat\" needs \"chased\" (to know what it did) and \"chased\" needs \"cat\" (to know who did it) — different reasons, but the score is forced to be the same.\n4. **Separate seeking/offering vectors break symmetry.** When `score(A, B) = dot(seek_A, offer_B)`, the scores become asymmetric because `seek_A` differs from `offer_A`. This is exactly what Q/K projections achieve in the next lesson.\n5. **Attention already creates context-dependent representations** — even raw dot-product attention changes \"bank\" based on surrounding words. But without asymmetric scores, its expressiveness is limited."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}